{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10ee54d-0935-4840-9182-c049f303ef60",
   "metadata": {},
   "source": [
    "# 这是一个演示Towhee流水线工程的示例项目\n",
    "\n",
    "## 组件\n",
    "向量数据库 : milvus \n",
    "\n",
    "## Example 1\n",
    "一个简单的towhee pipe演示程序，将输入数字增加1后输出。\n",
    "\n",
    "## Example 2\n",
    "演示如何将一个图片转换为向量，存入milvus向量数据库\n",
    "\n",
    "## Example 3 \n",
    "演示了sentence-t5-xxl 使用towhee pipe计算embedding，得到中文句子上的相似性计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316de60-3183-4a2b-9c17-0b8d2511d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb65da-48e2-43f7-8068-c9ac4e85f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_host = '127.0.0.1'\n",
    "milvus_port = '19530'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a536f283-e706-4b63-8e97-1524680310de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all-MiniLM-L12-v1', 'all-MiniLM-L12-v2', 'all-MiniLM-L6-v1', 'all-MiniLM-L6-v2', 'all-distilroberta-v1', 'all-mpnet-base-v1', 'all-mpnet-base-v2', 'all-roberta-large-v1', 'bert-base-nli-mean-tokens', 'bert-base-uncased', 'bert-large-uncased', 'bert-large-uncased-whole-word-masking', 'distilbert-base-uncased', 'distiluse-base-multilingual-cased-v1', 'distiluse-base-multilingual-cased-v2', 'facebook/bart-large', 'gpt2-xl', 'microsoft/deberta-xlarge', 'microsoft/deberta-xlarge-mnli', 'msmarco-bert-base-dot-v5', 'msmarco-distilbert-base-tas-b', 'msmarco-distilbert-base-v4', 'msmarco-distilbert-dot-v5', 'multi-qa-MiniLM-L6-cos-v1', 'multi-qa-MiniLM-L6-dot-v1', 'multi-qa-distilbert-cos-v1', 'multi-qa-distilbert-dot-v1', 'multi-qa-mpnet-base-cos-v1', 'multi-qa-mpnet-base-dot-v1', 'paraphrase-MiniLM-L12-v2', 'paraphrase-MiniLM-L3-v2', 'paraphrase-MiniLM-L6-v2', 'paraphrase-TinyBERT-L6-v2', 'paraphrase-albert-small-v2', 'paraphrase-distilroberta-base-v2', 'paraphrase-mpnet-base-v2', 'paraphrase-multilingual-MiniLM-L12-v2', 'paraphrase-multilingual-mpnet-base-v2']\n",
      "['all-MiniLM-L12-v1', 'bert-base-uncased', 'multi-qa-mpnet-base-dot-v1', 'paraphrase-MiniLM-L6-v2', 'paraphrase-TinyBERT-L6-v2', 'paraphrase-multilingual-mpnet-base-v2', 'facebook/bart-large', 'distilbert-base-uncased', 'multi-qa-distilbert-cos-v1', 'bert-base-nli-mean-tokens', 'paraphrase-MiniLM-L12-v2', 'msmarco-distilbert-dot-v5', 'paraphrase-albert-small-v2', 'paraphrase-mpnet-base-v2', 'microsoft/deberta-xlarge', 'all-MiniLM-L6-v1', 'all-roberta-large-v1', 'distiluse-base-multilingual-cased-v1', 'all-mpnet-base-v2', 'paraphrase-MiniLM-L3-v2', 'multi-qa-MiniLM-L6-cos-v1', 'bert-large-uncased', 'all-distilroberta-v1', 'all-mpnet-base-v1', 'msmarco-bert-base-dot-v5', 'bert-large-uncased-whole-word-masking', 'multi-qa-mpnet-base-cos-v1', 'distiluse-base-multilingual-cased-v2', 'paraphrase-multilingual-MiniLM-L12-v2', 'all-MiniLM-L12-v2', 'microsoft/deberta-xlarge-mnli', 'multi-qa-MiniLM-L6-dot-v1', 'msmarco-distilbert-base-v4', 'paraphrase-distilroberta-base-v2', 'all-MiniLM-L6-v2', 'multi-qa-distilbert-dot-v1', 'msmarco-distilbert-base-tas-b']\n"
     ]
    }
   ],
   "source": [
    "# 列出所有towhee支持的model\n",
    "from towhee import ops\n",
    "\n",
    "op = ops.sentence_embedding.transformers().get_op()\n",
    "full_list = op.supported_model_names()\n",
    "onnx_list = op.supported_model_names(format = 'onnx')\n",
    "\n",
    "print(full_list)\n",
    "print(onnx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a166a76-bfbf-4374-96cf-8c140951bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "from towhee import pipe\n",
    "\n",
    "add_one = (\n",
    "    pipe.input('x')\n",
    "        .map('x', 'y', lambda x: x+1)\n",
    "        .output('y')\n",
    ")\n",
    "\n",
    "res = add_one(0).get()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e29d7-e7c9-47ab-8099-17364eaf54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "from towhee import pipe, ops\n",
    "\n",
    "img_embedding = (\n",
    "    pipe.input('url')\n",
    "        .map('url', 'img', ops.image_decode.cv2())\n",
    "        .map('img', 'embedding', ops.image_embedding.timm(model_name = 'resnet50'))\n",
    "        .output('embedding')\n",
    ")\n",
    "\n",
    "url = 'pic/test1.jpg'\n",
    "res = img_embedding(url).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a98cb2-6788-472e-b3a0-bdd32d3321e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, utility, connections\n",
    "import pandas as pd\n",
    "collection_name = 'pcapel_towhee'\n",
    "print(res)\n",
    "# 假定已经创建milvus collection：pcapel_towhee\n",
    "connections.connect(host=milvus_host, port=milvus_port)\n",
    "collection = Collection(collection_name)\n",
    "\n",
    "df = pd.DataFrame({'id':[1], 'name':['test'], 'embedding':[res[0]]})\n",
    "# print(dict1)\n",
    "collection.insert( df.to_dict(orient = 'records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214e3584-b587-4eec-8cfa-096105498054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3 \n",
    "from towhee import pipe, AutoConfig, AutoPipes\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "auto_config = AutoConfig.load_config('sentence_embedding')\n",
    "## https://huggingface.co/sentence-transformers/sentence-t5-xxl\n",
    "auto_config.model = 'sentence-t5-xxl'\n",
    "auto_config.device = -1\n",
    "\n",
    "sentence_embedding = AutoPipes.pipeline('sentence_embedding', config=auto_config)\n",
    "\n",
    "\n",
    "def start_thread_embedding(text): \n",
    "    return torch.tensor(sentence_embedding(text).get(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb81815-14d1-493e-959b-9038430b6b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu :  12\n",
      "执行时长: 0.0827 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/data-processing-v2/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/data-processing-v2/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'print_text' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "# 中文 Sentence Token\n",
    "text1 = '随着科技的快速发展，人工智能在我们的生活中扮演着越来越重要的角色，从智能家居到自动驾驶汽车，它的应用领域日益广泛。'\n",
    "text2 = '科技进步带动了人工智能技术的飞速发展，它已经深入到我们生活的各个方面，包括智能家电和自动化交通工具，成为不可或缺的一部分。'\n",
    "\n",
    "# embedding1 = start_thread_embedding('随着科技的快速发展，人工智能在我们的生活中扮演着越来越重要的角色，从智能家居到自动驾驶汽车，它的应用领域日益广泛。')\n",
    "# embedding2 = start_thread_embedding('科技进步带动了人工智能技术的飞速发展，它已经深入到我们生活的各个方面，包括智能家电和自动化交通工具，成为不可或缺的一部分。')\n",
    "# with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "#     embedding1 = executor.submit(start_thread_embedding, text1).result()\n",
    "#     embedding2 = executor.submit(start_thread_embedding, text2).result()\n",
    "# executor = ThreadPoolExecutor(max_workers=5)\n",
    "# for result in executor.map(start_thread_embedding, [text1, text2]):\n",
    "#     print(f\"完成向量化\")\n",
    "# executor.shutdown()\n",
    "# start_time = time.time()\n",
    "# print(\"Number of cpu : \", multiprocessing.cpu_count())\n",
    "# p = multiprocessing.Process(target=print_text, args=(text1,))\n",
    "# p.start()\n",
    "# p.join()\n",
    "end_time = time.time()\n",
    "print(f\"执行时长: {end_time - start_time:.4f} 秒\")\n",
    "\n",
    "# consin_sim = F.cosine_similarity(embedding1.float(), embedding2.float())\n",
    "# print(consin_sim.item())\n",
    "# batch generate embeddings for multi-sentences\n",
    "# embeddings = sentence_embedding.batch(['how are you?', 'how old are you?'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "864a6857-797b-4ded-b0a5-203b63f5c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test2\n",
      "test\n",
      "test2\n"
     ]
    }
   ],
   "source": [
    "# import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def print_text(str = 'anon'):\n",
    "    print(f\"{str}\")\n",
    "    return str\n",
    "\n",
    "\n",
    "# threads = []\n",
    "# thread = threading.Thread(target=print_text, args=('anon1',))\n",
    "# threads.append(thread)\n",
    "# thread.start()\n",
    "# thread.join()\n",
    "\n",
    "\n",
    "# 创建线程池\n",
    "with ThreadPoolExecutor(max_workers=4) as pool:\n",
    "    # 提交任务\n",
    "    results = pool.map(print_text, ('test', 'test2'))\n",
    "\n",
    "# 打印结果\n",
    "for r in results:\n",
    "    print(f\"{r}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
